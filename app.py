import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.metrics import (
    r2_score, root_mean_squared_error, mean_absolute_error,
    accuracy_score, confusion_matrix, classification_report
)
from sklearn import tree

# ---------------- Page Config ----------------
st.set_page_config(page_title="DT Regression & Classification", layout="wide")
st.title("üè† California Housing ‚Äì Decision Tree")

# ---------------- Upload ----------------
file = st.sidebar.file_uploader(
    "Upload california_housing_test.csv",
    type="csv"
)

if file:
    df = pd.read_csv(file)

    st.subheader("Dataset Preview")
    st.dataframe(df.head())

    # ---------------- FIX: One-Hot Encoding ----------------
    if "ocean_proximity" in df.columns:
        df = pd.get_dummies(
            df,
            columns=["ocean_proximity"],
            drop_first=True
        )

    # ---------------- Features & Targets ----------------
    X = df.drop(columns="median_house_value")
    y_reg = df["median_house_value"]

    # Convert regression target to classes
    y_class = pd.qcut(y_reg, q=3, labels=[0, 1, 2])

    # ---------------- Sidebar ----------------
    st.sidebar.header("Model Selection")

    task = st.sidebar.selectbox(
        "Select Task",
        ["Regression", "Classification"]
    )

    technique = st.sidebar.selectbox(
        "Select Technique",
        ["Pre-Pruning", "Post-Pruning"]
    )

    # ========================= REGRESSION =========================
    if task == "Regression":
        st.subheader("Decision Tree Regression")

        X_train, X_test, y_train, y_test = train_test_split(
            X, y_reg, test_size=0.2, random_state=42
        )

        # ---------- Pre-Pruning ----------
        if technique == "Pre-Pruning":
            max_depth = st.sidebar.slider("Max Depth", 1, 20, 5)
            min_samples_split = st.sidebar.slider("Min Samples Split", 2, 20, 2)

            model = DecisionTreeRegressor(
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42
            )

        # ---------- Post-Pruning ----------
        else:
            base = DecisionTreeRegressor(random_state=42)
            path = base.cost_complexity_pruning_path(X_train, y_train)

            ccp_alpha = st.sidebar.slider(
                "ccp_alpha",
                float(path.ccp_alphas.min()),
                float(path.ccp_alphas.max()),
                step=0.0005
            )

            model = DecisionTreeRegressor(
                random_state=42,
                ccp_alpha=ccp_alpha
            )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        st.write("R¬≤ Score:", round(r2_score(y_test, y_pred), 4))
        st.write("RMSE:", round(root_mean_squared_error(y_test, y_pred), 2))
        st.write("MAE:", round(mean_absolute_error(y_test, y_pred), 2))

    # ========================= CLASSIFICATION =========================
    else:
        st.subheader("Decision Tree Classification")

        X_train, X_test, y_train, y_test = train_test_split(
            X, y_class, test_size=0.2, random_state=42
        )

        # ---------- Pre-Pruning ----------
        if technique == "Pre-Pruning":
            max_depth = st.sidebar.slider("Max Depth", 1, 20, 5)
            min_samples_split = st.sidebar.slider("Min Samples Split", 2, 20, 2)

            model = DecisionTreeClassifier(
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42
            )

        # ---------- Post-Pruning ----------
        else:
            base = DecisionTreeClassifier(random_state=42)
            path = base.cost_complexity_pruning_path(X_train, y_train)

            ccp_alpha = st.sidebar.slider(
                "ccp_alpha",
                float(path.ccp_alphas.min()),
                float(path.ccp_alphas.max()),
                step=0.0005
            )

            model = DecisionTreeClassifier(
                random_state=42,
                ccp_alpha=ccp_alpha
            )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        st.write("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
        st.write("Confusion Matrix")
        st.write(confusion_matrix(y_test, y_pred))
        st.text("Classification Report")
        st.text(classification_report(y_test, y_pred))

    # ---------------- Tree Visualization ----------------
    st.subheader("Decision Tree Visualization")

    fig, ax = plt.subplots(figsize=(20, 10))
    tree.plot_tree(
        model,
        feature_names=X.columns,
        filled=True,
        max_depth=3,
        ax=ax
    )
    st.pyplot(fig)
